---
title: "üöó OutVenture: In-Car Educational AR Chatbot System"
collection: projects
permalink: /projects/2023-06-08-In-car-Voice-Chatbot-OutVenture/
excerpt: 'An in-car multimodal AR chatbot system that provides real-time landmark explanations through vision and speech.'
date: 2023-06-08
---

As part of the **AI Capstone Design Project Course** jointly hosted by **LG Electronics** and **Sogang University** during Spring 2023, our team developed an **in-car educational AR chatbot system** called **OutVenture**. Supervised by Prof. Jeung Uk Ha, this project aimed to enhance the passenger experience‚Äîespecially for children‚Äîby providing real-time information about outside landmarks while driving.

The system was built within a Unity 3D simulation environment, replicating the view from inside a moving vehicle. Using computer vision, it detects and classifies real-world landmarks visible through the window. Once a landmark is recognized, a voice-based AI chatbot delivers an educational explanation about it through real-time speech synthesis.

The goal was to create an interactive, multimodal experience that combines image classification, speech processing, and 3D game simulation into a cohesive AR-assisted learning platform.

---

### üîÅ System Flow

![OutVenture Flow Chart](/images/outventure_flow_chart.png)

---

### ‚ñ∂Ô∏è Demo Video

Vimeo: [https://vimeo.com/898732114](https://vimeo.com/898732114)

---

### My Contribution

I was primarily responsible for building the real-time image classification model using ResNet-18, which was integrated into the Unity environment via PyAutoGUI. To improve both accuracy and efficiency, I extended the model to be multimodal, incorporating not only visual input (images) but also positional metadata such as coordinates and viewing angles from within the Unity simulation.

In addition, I designed the chatbot integration pipeline, which connected the outputs of the classification model to a voice-based chatbot using external APIs. The chatbot used the model's predictions to provide real-time, educational explanations about recognized landmarks through speech synthesis.
